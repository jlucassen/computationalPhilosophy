TECHNICAL DOCUMENTATION

Here I will generally explain what all this stuff does, at the code level. 
Different experiments will be listed alphabetically, and within each of
those experiment subsections the functions will be listed alphabetically too. 

TABLE OF CONTENTS
    3body
    evoSim
    findIsland
    lookElsewhere
    lorenz
    reverseBabel
    sdSim

3body
    calculateForce
        Input: two bodies, VPython objects with values representing position
        assigned to pos and values representing mass assigned to m. 

        Output: force exerted on first body by second body, as a VPython
        vector. Calculated according to Newton's Law of Universal 
        Gravitation, using G=1. 

        How it works: Finds relative position vector, converts it to a unit
        vector, and then plugs into the formula F=Gmm/r**2.

        Known bug: discrete time stepping can break energy conservation. If
        bodies get very close, they will exert massive forces on each other,
        causing them to move extremely fast and get far away from each other
        within one time step, so no equally massive force is applied in the
        opposite direction as it should be. Increasing time step resolution
        can actually make this worse, not better, since they can get closer to
        each other and exert bigger forces before exploding apart. But hey,
        the goal here is to learn about chaos, not to actually predict any
        celestial bodies. Explosions are a particularly strong nonlinearity.
        Ta-da, it's a feature!
    
    nBody
        Input: parameter information for any number of bodies, as a list of
        dictionaries with values keyed by parameter name. Can also take a 
        length of time to simulate and a time step to use, but defaults are 
        100 and 0.01. Required body parameters are pos, vel, and m. Pos and 
        vel are VPython vectors represeting initial position and velocity,
        m is a float representing particle mass.

        Output: simulates motion based on initial conditions using VPython to
        visualize the 3-D motion.
        
        How it works: Unwraps parameters from dictionaries and creates scene.
        Main loop first uses calculateForce to find forces on each body, then
        uses f=ma to calculate new velocities for each particule, uses new 
        velocities to find new positions for each particle at next time step,
        and repeats. VPython takes care of all the animation.

    nBodyParallel
        Input: parameter information for multiple nBody-like simulations, as a
        list of lists of dictionaries (I know, ew). Upper level separates the
        data for each simulation, next level separates data for each body,
        lowest level contains the values for each parameter. Required fields are
        exactly the same as nBody - basically just a bunch of nBody simulations
        stapled together into a list.

        Output: simulates motion of each set of parameters in parallel.

        How it works: Creates separate scenes for each set of parameters and
        unwraps parameters from dictionaries. Runs much like nBody, but within
        each time step iterates through each scene to run them all in parallel.

    plotDivergence
        Input: parameter information for for exactly three bodies. Also takes
        time and time step, which default to 100 and 0.01. Finally, takes a 
        list of permutation factors, as a list of floats. 
        
        Output: Runs a nBody-like simulation for each factor, multiplying all
        initial positions and velocities by that factor. Once all sims have run
        plots the divergence of each perturbed simulation from the original
        over time using its phase space distance.

        How it works: As sims run, records the history of the system as an
        18-dimensional phase space vector for each time step. Phase space is
        composed of position and momentum, for each of three bodies. Once all
        have run, find the magnitude of the difference between each vector
        throughout the history of each permutation, and graphs the result.

    threeBodyPlus
        Input: parameter information for exactly three bodies, as dictionaries
        keyed by parameter name. Also takes time and time step, default to 100
        and 0.01. Also takes three booleans, center, plane, and norm, all of
        which default to False. Required fields are the same as nBody.

        Output: Runs a simulation like nBody, but limited to exactly three
        bodies. Binary parameters turn on successive extra features. If center
        is True, a point will trace the center of mass of the system. If center
        and plane are True, a polygon will indicate the plane of the three
        bodies, and the center of mass. If all three are True, the camera will
        stay normal to the plane of the bodies, and their trails will be turned
        off.

        How it works: Based on nBody. Center of mass position is the average of
        the bodies' positions, weighted by mass. Plane creates a triangle, with
        the locations of the bodies as vertices, and adds their colors to help
        it look more 3-D. Norm gets the cross product of the relative positions
        of two bodies relative to the COM, and sets it to constant magnitude.
        Scene camera is kept at the location of the COM plus this vector, and 
        points in the opposite direction of this vector (towards COM).

evoSim
    basicSim
        Input: takes a number of individuals, a number of generations, a
        mutation probability, and an initial gene maximum. 

        Output: returns the complete history of the simulation as a list of
        lists of floats - each list represents a generation, with each float
        in a generation representing an individual.
        
        How it works: Each individual is represented by a float, their
        survival chance. Each generation kills individuals according to their
        survival chance, and then repopulates back up to the starting number
        of individuals, with a certain mutation chance. When a mutation occurs
        a new individual is generated randomly and added.

    plotHistory
        Input: takes a complete simulation history, a popType string to specify
        how to interpret, a bool to plot variance or not, a label string, and 
        a bool to show class plots or not (only matters in trait mode).

        Output: in basic mode, plots the average of the survival chance for
        each generation in the sim history, and does the same for variance if 
        told to. Appends the label to the start of each plot title, default is
        empty string. In poly mode, does the same for each gene individually.
        Doesn't plt.show(), so user can plot multiple sims before showing. In
        trait mode, always plots survival gene and trait gene, and if told to
        make class plots, will also show survival gene and trait gene for class
        with trait and class without. Shows variance for all if told to, but
        that's a lot of graphs.

        How it works: in basic mode, pretty much just creates a figure, sets
        various parameters appropriately, and spits it out. In poly mode,
        converts to numpy array first to more easuly fetch data as lists on a
        gene-by-gene basis, but then pretty much does the same. In trait mode,
        if not showing class plots then very similar to poly mode, but without
        flexibility in the number of genes plotted. If showing class plots then
        has to iterate through the whole history and sort data into classes
        before plotting. 

    plotSliceHistogram
        Input: a list of individuals representing a generation, and a popType
        string to specify how to interpret.

        Output: in basic mode, plots and shows a histogram of the population's
        survival chances. In poly mode, plots each gene as its own histogram.

        How it works: in basic mode, just a wrapper for plt.hist(). In poly
        mode, converts to numpy array first to more easily fetch data as lists
        on a gene-by-gene basis.

    polySim
        Input: takes a number of individuals, a number of generations, a
        mutation probability, an initial gene max, and a list of gene weights.

        Output: returns the complete history of the simulation as a list of
        lists of lists of floats. Each list of lists represents a generation,
        containing lists representing individuals, which contain float genes.

        How it works: each individual is represented as a list of float genes.
        Each generation, their survival chance is the weighted sum of their
        genes. Each generation kills individuals according to their survival
        chance, and then repopulates back up to the starting number, with a
        certain mutation chance. Mutation individuals are generated randomly.

    printSliceMembers
        Input: a list of individuals representing a generation

        Output: prints all individuals one by one

        How it works: for loop and print my guy

    printSliceSummary
        Input: a list of individuals representing a generation, and a popType
        string to specify how to interpret.

        Output: in basic mode, prints average and variance of individuals'
        survival chances. In poly mode, prints average and variance for each
        gene separately.

        How it works: in basic mode, basically a wrapper for statistics.mean.
        In poly mode, converts to numpy array first to more easily fetch data
        as lists on a gene-by-gene basis.

    traitSim
        Input: takes a number of individuals, a number of generations, a
        mutation probability, and an initial gene max.

        Output: returns the complete history of the simulation as a list of
        lists of lists. The list representing the whole history contains lists
        each representing a generation. The generation lists contain lists
        representing individuals. The individual lists contain a float survival
        gene, a float trait gene, and a binary trait.

        How it works: each individual is represented as a list, and the trait
        value is recalculated every generation with probability equal to the
        trait gene. Each generation kills individuals based on their survival
        chance, and then repopulates back up to the starting number, with a
        certain mutation chance. Mutation individuals are generated randomly.
        The binary trait is completely inert.

findIsland 
    findIsland
        Input: void to the function itself, but takes in an api key and a root
        word through the terminal

        Output: identifies the size of the "island" centered around the root
        word

        How it works: passes words through three lists, called island, shore,
        and sea. Island and sea start empty, shore starts as just the root
        word. Uses the Merriam Webster Dictionary API to fill the sea with all
        words used in all the definitions of the words in the shore that are 
        not already included in the sea, shore, or island. Then shore is added
        to island, sea becomes shore, and sea is emptied before next cycle. 
        Continues until a cycle tries to start with shore empty, meaning no new
        words were found in the previous cycle.

lookElsewhere
    basic
        Input: takes in a number of variables, a number of data points per
        variable, a target p-value, and a boolean to specify whether or not to
        display the strongest correlation found.

        Output: prints the number of false correlations that arise between the
        variables that are considered significant based on the p-value. If 
        showBest is True, will display the data that displayed the strongest
        correlation

        How it works: generates random data for each variable, and iterates
        through all pairs of data testing for a significant correlation. Counts
        the number found, and reports it. If showBest is True, also tracks the
        most impressive correlation, and displays it at the end.
    
    plotEffect2d
        Input: takes in a maximum number of variables, a maximum number of data
        points, a step to increment variables by, a step to increment data 
        points by, and a boolean to indicate whether to use the Bonferroni
        correction or not.

        Output: Graphs the number of false correlations that arise at each 
        combination of variables tested and data points per variable

        How it works: Iterates from 2 variables and 3 data points up through
        the maxima, stepping each by the appropriate interval. Calls basic()
        to count the number of false correlations that arise, using p < 0.05.
        If Bonferroni is turned on, calls basic with 0.05/(numVars choose 2) as
        the p-value, since there is a hypothesis being tested for each pair of
        variables.

    plotPointEffect
        Input: takes in a number of variables to use, a maximum number of data
        points, a number to increment points by, a number of times to repeat
        each trial, a number of derivatives to show, and a boolean to use the
        Bonferroni correction or not.

        Output: Graphs the number of false correlations that arise at each
        number of data points from 3 up to maxPoints, stepping by pointStep.
        Plots the number of derivatives specified as well.

        How it works: Iterates from 3 (min number of points for pearson to give
        a meaningful assessment of correlation) up through maxPoints, stepping
        up by pointStep. Each time, calls basic() to count the number of false
        correlations that show up. Uses p < 0.05. Repeats each trial 'repeat'
        times, since higher derivatives need accuracy. Plots results, and also
        plots the number of derivatives specified. If Bonferroni is turned on,
        calls basic with 0.05/(numVars choose 2) as the p-value, since there is
        a hypothesis being tested for each pair of variables.

    plotVarEffect
        Input: takes in a maximum number of variables, a number of data points,
        a step to increment the variables used by, a number of times to repeat
        each trial, a number of derivatives to show, and a boolean to use the
        Bonferroni correction or not.

        Output: Graphs the number of false correlations that arise at each
        variable number from 2 up to maxVars, stepping by varStep. Plots the
        number of derivatives specified as well.

        How it works: Iterates from 2 (min # of variables to have a pair to
        test) up through maxVars, incrementing by varStep. Each time, calls
        basic() to count the number of illusory correlations that show up. 
        Calls basic with a p value of 0.05, since that's the standard. Repeats
        each trial 'repeat' times, and averages the results, since accuracy is
        needed to plot higher derivatives. Plots results, and also plots the
        specified number of derivatives. If the Bonferroni correction is turned
        on, calls basic with 0.05/(numVars choose 2) as the p-value, since
        there is a hypothesis being tested for each pair of variables.

lorenz
    errorExplosion
        Input: system parameters rho, sigma, and beta, an amount of time to
        simulate, and a time step size to use.

        Output: graphs the distances between a randomly selected "anchor"
        state somewhere within a 10x10x10 cube of the origin, and three other
        states separated from it in all three dimensions by progressively
        smaller amounts (0.01, 0.00001, 0.00000001)

        How it works: basically just a wrapper for trackError. Picks an anchor
        state at random, and then calls trackError three times, for the three
        incremental errors.

    mapField
        Input: system parameters rho, sigma, and beta, as well as a zone to map
        the field in, a spacing between points shown, and a bunch of booleans
        that indicate whether to show colors or not, show arrows or spheres,
        and scale vectors to the same length or not. Also a scale for the size
        of the arrows/spheres, and a center for the zone of mapping as an array
        of coordinates.

        Output: draws the field accordingly, either color-coded or white,
        arrows or spheres, unit vectors or vectors with their magnitude scaled.

        How it works: iterates through the coordinates from -zone to zone for
        x, y, and z, incrementing by the spacing. At each location, call move()
        to determine the vector there. If colors are turned on, codes the 
        direction of the vector into a color. Draws the representation it's
        told to by all those setting parameters with vPython.

    move
        Input: an x-coordinate, y-coordinate, and z-coordinate, as well as the
        system parameters rho, sigma, and beta

        Output: the x,y,z derivatives, as a list

        How it works: plugs into the Lorenz equations

    multiSim
        Input: a list of lists of numbers containing starting coordinates, and
        the parameters rho, sigma, and beta, an amount of time to simulate, the
        size of the discrete time step to use, a value to determine if/how to 
        plot the vector field, and a frame rate to use.

        Output: animates the evolution of the starting states according to the
        system parameters given. Runs until the end of the time allotted, using
        the discrete time step given. If left to default, field will not be
        plotted, but if user passes in an argument dictionary, calls mapField()
        using those parameters to show the vector field superimposed onto the
        movement of the state.

        How it works: Basically just loops and ticks through the time, on each
        tick iterates through each of the states being simulated, and for each,
        calls move() and passes in the appropriate parameters, then updates the
        positions of the vPython objects accordingly.

    paramPlaneStability
        Input: two starting states as coordinate lists, the system parameter
        rho, an amount of time to simulate, a time step to use, a zone to test
        (in sigma-beta parameter space), and a threshold for when two states 
        are considered separated.

        Output: produces a 2-d heatmap of sigma-beta parameter space, where the
        color of each space represents the log of the time it takes for the two
        states given to separate by the given threshold, in a system with the
        parameters indicated (r is fixed since it seems to be important that
        r=28, online sources mention that the lorenz attractor is chaotic for
        this specific value of r). If a configuration doesn't separate in the
        time given, it is assigned the maximum value. Log used because times
        vary so much.

        How it works: iterates through each combination of s and b, runs a sim
        with those parameters using lists, not vPython, and checks distance
        between the two states that were given at each time step. If threshold
        exceeded, stops simulation and records time. When all done, plots 
        heatmap.

    singleSim
        Input: a starting x-coordinate, y-coordinate, and z-coordinate, as well
        as the system parameters rho, sigma, and beta, an amount of time to
        simulate, the size of the discrete time step to use, a value to
        determine if/how to plot the vector field, and a frame rate to use.

        Output: animates the evolution of the starting state according to the 
        system parameters given. Runs until the end of the time allotted, using
        the discrete time step given. If left to default, field will not be
        plotted, but if user passes in an argument dictionary, calls mapField()
        using those parameters to show the vector field superimposed onto the
        movement of the state.

        How it works: Basically just loops and ticks through the time, on each
        tick calls move() and passes in the appropriate parameters, then
        updates the positions of the vPython objects accordingly.

    spatialPlaneFractal
        Input: a z-coordinate, rho, sigma, and beta, a time to simulate, a time
        step to use, zone half edge length, a spacing between observations, and
        a center for the zone to represent.

        Output: produces a 2d heatmap of the x-y plane, where the color of each
        space represents where in 3-space it ends up after the amount of time
        specified. Goal was to try and determine how adjacent states diverge
        over time.

        How it works: iterates through each combination of x and y, runs a sim
        with those start coordinates, and records where it ends up in 3-space.
        Keeps track of the most extreme + and - x, y, and z values. After all
        sims have run, iterates through all the coordinates and scales x, y, z
        to fall between 0 and 1, so they can be taken as RGB colors. Produces
        heatmap with those colors.

    spatialPlaneStability
        Input:a z-coordinate, as well as system parameters rho, sigma, and
        beta, a time to simulate, a time step to use, a zone to simulate, and
        a threshold at which states are considered separated.

        Output: produces a 2d heatmap of the x-y plane, where the color of each
        space represents the time it takes two slightly separated starting
        states to diverge. Goal is to see if divergence of states is continuous
        or if there's certain regions where states tend to diverge.

        How it works: iterates through each combination of x and y, runs a sim
        with those start coordinates (0.001 apart) using lists, checks distance
        between the two states that were given at each time step. If threshold
        exceeded, stops simulation and records time. When all done, plots 
        heatmap.

    trackError
        Input: two starting states, as lists of coordinates, as well as the
        system parameters rho, sigma, and beta, an amount of time to simulate,
        and a time step to use

        Output: Graphs the magnitude of the distance between the two states
        over time

        How it works: runs each simulation in parallel by stepping through time
        and calling move(), just like multiSim, but stores info in lists, not
        vPython objects. Records the distance between the two calculated by
        pythagorean theorem, and plots the results at the end.

reverseBabel
    generateCorpus
        Input: first parameter is an alphabet, as a dictionary with symbols
        as keys and their respective frequencies as their values. These
        frequencies should sum to 1, or things will break. Second parameter
        is the initial probability to terminate a word, or the probability
        to generate a one-letter word. Third parameter is the factor by which
        word termination probability increases with each additional letter. 
        Fourth parameter is the number of distinct words that should be
        generated before corpus generation stops. Default values are tuned 
        to match natural English.

        Output: an artifical language corpus, as a dictionary with words as
        keys, and the number of times each word was generated as its value.

        How it works: Generates words by successively appending letters based
        on their frequencies, increasing the probability of termination until
        the word is terminated. If a word has been generated before, its value
        is incremented by 1. Generation continues until a sufficient number of
        distinct words have been generated.

    generateSentence
        Input: a corpus, as dictionary of words as keys with the number of 
        times generated as their values. Also takes an average sentence length,
        which defaults to 15, to match natural English.

        Output: a sentence from the given corpus, as a list of strings.

        How it works: Determines a sentence length by pulling from a Poisson
        distribution centered around average sentence length. Pulls words based
        on their frequencies from the corpus, until sentence length is reached.

    plotCorpus
        Input: a corpus, as dictionary of words as keys with the number of 
        times generated as their values. 
        
        Output: Plots a distribution of the lengths of the words in the corpus,
        un-weighted by use. Also makess a Zipf plot of word frequency vs word
        frequency rank, in both linear and log-log domains. Finally, prints 
        mean word length, without weighting for usage.
        
        How it works: sorts all words in order by length, and by frequency.
        Plots results using matplotlib.pyplot.

    printSentence
        Input: a sentence, as a list of strings.

        Output: prints sentence space-delimited, with the first letter
        capitalized, and with a period at the end.

        How it works: It's basically just a slightly specialized wrapper for
        str.join(), not gonna lie.

    simExchange
        Input: a number of samples to attempt.

        Output: the number of sentences generated in one generateCorpus corpus
        where every word in the sentence is also a member of an independently
        generated corpus.

        How it works: uses generateCorpus to produce two corpora. From one,
        generates a sentence, and checks it word-by-word to see if it fits in
        the other. If any word is not found, the sentence is rejected. Repeats
        for the specified number of attempts, and then returns the number of
        successfully matched sentences.

sdSim
    multiSim
        Input: a function, and a list of dictionaries containing different 
        sets of parameters to run that function with.

        Output: Applies each set of parameters to the function, and graphs each
        case in a separate figure.

        How it works: Unwraps parameters from dict and passes to function, 
        storing output in a list of dicts. After iterating through all sets of
        parameters, passes the results list directly to plotMulti to graph.

    plotMulti
        Input: a list of dicts of lists (ew), where each dict contains the
        history of all groups for a simulation. 

        Output: plots the data from each simulation on a separate figure, and
        plots each simulation the same as plotOne.

        How it works: iterates through the dicts in the list, and for each dict
        corresponding to a simulation iterates through all lists in that dict,
        plotting the history of each group the same as plotOne.

    plotOne
        Input: a dict of lists, where each list contains the history for a 
        group and is keyed by group name.

        Output: graphs each population's history, with labels

        How it works: iterates through all lists in the dict, plotting each
        on the same figure
    
    SEIR
        Input: a whole bunch of floats. S0 is initial suceptible population,
        E0 is initial exposed, I0 is initial infected, R0 is initial recovered.
        ic is incubation coefficient, reciprocal of incubation period in days.
        cc0 is a component of the contact coefficient, found by R0*rc. rc is
        recovery coefficient, reciprocal of recovery time in days. t is number
        of days to simulate.

        Output: graphs all populations at each time step, according to SEIR
        epidemiological model

        How it works: determines change in each population according to SEIR
        equations, stores each population's history in a list, returns a dict
        of all population lists, keyed by population name.

    SEIRD
        Input: the same as SEIR(), but includes D0 for initial casualties, 
        dc as the death coefficient, medCap as the capacity of the medical
        system, and medRate as the hospitalization rate of the disease.

        Output: Graphs all populations at each time step, according to SEIR
        model modified to account for deaths and not just recoveries.

        How it works: exactly the same as SEIR, but adds an extra bin and an
        extra equation to calculate how many people die and how many recover
        when leaving the I group. Death rate is based 

    SEIRD_sd
        Input: the same as SEIRD_sd(), but includes sd as the max social
        distancing factor, lag as the social distancing policy decision making
        lag, and step as the interval between adjustments made to social
        distancing policy.

        Output: Graphs all populations at each time step, affected by social
        distancing policies

        How it works: Social distancing coefficient scales inversely with
        proportion of population infected, from 1 at 0% to 1/sd at 100%. New 
        infections are multiplied by the social distancing coefficient. Social
        distancing policy is updated periodically according to step, and made
        based on old data according to lag. If lag>0, social distancing policy
        is suppressed entirely for at the start for the lag duration, as there
        is no data available.